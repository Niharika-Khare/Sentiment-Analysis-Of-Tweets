{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A                                                  F\n",
      "0  0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1  0  is upset that he can't update his Facebook by ...\n",
      "2  0  @Kenichan I dived many times for the ball. Man...\n",
      "3  0    my whole body feels itchy and like its on fire \n",
      "4  0  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"../input_data/data.csv\", names=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"])\n",
    "df = df.drop([\"B\",\"C\",\"D\",\"E\"], axis=1)\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 2)\n",
      "(960000, 2)\n",
      "(320000, 2)\n",
      "(320000, 2)\n"
     ]
    }
   ],
   "source": [
    "y = df.drop([\"A\"],axis=1)\n",
    "X = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "print df.shape\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from porter_stemmer import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "def processTweet(tweet):\n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    #remove @username\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    # Remove tickers\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # To lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    # remove non ascii\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]',' ', tweet)\n",
    "    # Remove Punctuation and split 's, 't, 've with a space for filter\n",
    "    tweet = re.sub(r'[' + string.punctuation.replace('@', '') + ']+', ' ', tweet)\n",
    "    # remove anythin that is not alphanumeric\n",
    "    tweet = re.sub('[\\W_]+', ' ', tweet) \n",
    "    # Remove words with 2 or fewer letters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    # Remove single space remaining at the front of the tweet.\n",
    "    tweet = tweet.lstrip(' ')  \n",
    "    # Removing Stopwords from tweet using sklearn.feature_extraction\n",
    "    split_list = tweet.split(\" \")\n",
    "    tweet = [ word for word in split_list if word not in stop_words.ENGLISH_STOP_WORDS ]\n",
    "    # Stemming the \n",
    "    ps = PorterStemmer()\n",
    "#     print tweet\n",
    "#     t = []\n",
    "#     for word in tweet:\n",
    "#         print word\n",
    "#         t.append(ps.stem(word))\n",
    "    tweet = [ ps.stem(word) for word in tweet ] \n",
    "#     tweet = t\n",
    "    tweet = ' '.join(tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "processed_data = list()\n",
    "# k = 1\n",
    "for index, row in X_train.iterrows():\n",
    "    processed_data.append(processTweet(row['F']))\n",
    "#     k+=1\n",
    "#     if k==5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>F</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1546035</th>\n",
       "      <td>4</td>\n",
       "      <td>@Bzelasko u should be u have til december</td>\n",
       "      <td>til decemb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069916</th>\n",
       "      <td>4</td>\n",
       "      <td>skipped the morning run, but renewed gym membe...</td>\n",
       "      <td>skip mor run renew gym membership great workou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389400</th>\n",
       "      <td>0</td>\n",
       "      <td>@terri5me2000 Doing pretty well. Trying to get...</td>\n",
       "      <td>do pretti trying hous readi stuff prepar mom b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201870</th>\n",
       "      <td>0</td>\n",
       "      <td>@norahxx it's not fun to be sick</td>\n",
       "      <td>fun sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210348</th>\n",
       "      <td>4</td>\n",
       "      <td>@Billy3G sometimes I'm chill and easily entert...</td>\n",
       "      <td>chill easili entertain royal pain ars dai peop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         A                                                  F  \\\n",
       "1546035  4         @Bzelasko u should be u have til december    \n",
       "1069916  4  skipped the morning run, but renewed gym membe...   \n",
       "389400   0  @terri5me2000 Doing pretty well. Trying to get...   \n",
       "201870   0                  @norahxx it's not fun to be sick    \n",
       "1210348  4  @Billy3G sometimes I'm chill and easily entert...   \n",
       "\n",
       "                                                 processed  \n",
       "1546035                                        til decemb   \n",
       "1069916  skip mor run renew gym membership great workou...  \n",
       "389400   do pretti trying hous readi stuff prepar mom b...  \n",
       "201870                                           fun sick   \n",
       "1210348  chill easili entertain royal pain ars dai peop...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print processed_data\n",
    "X_train['processed'] = processed_data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'actual', u'amaz', u'awai', u'awesom', u'aww', u'babi', u'bad', u'beauti', u'bed', u'best', u'better', u'big', u'birthdai', u'bit', u'boi', u'book', u'bore', u'bui', u'busi', u'car', u'check', u'cold', u'com', u'come', u'cool', u'dai', u'damn', u'did', u'didn', u'do', u'doe', u'doesn', u'don', u'dont', u'earli', u'eat', u'end', u'enjoi', u'exam', u'excit', u'famili', u'feel', u'final', u'finis', u'follow', u'fridai', u'friend', u'fun', u'game', u'get', u'girl', u'glad', u'go', u'god', u'gone', u'gonna', u'good', u'got', u'gotta', u'great', u'guess', u'gui', u'haha', u'hair', u'happen', u'happi', u'hard', u'hate', u'have', u'haven', u'head', u'hear', u'hei', u'help', u'home', u'hope', u'hot', u'hour', u'hous', u'hurt', u'job', u'just', u'kid', u'know', u'late', u'later', u'leav', u'left', u'let', u'life', u'like', u'listen', u'littl', u'live', u'lol', u'long', u'look', u'lost', u'lot', u'love', u'luck', u'make', u'man', u'mayb', u'mean', u'meet', u'miss', u'mom', u'mondai', u'mor', u'movi', u'music', u'need', u'new', u'nice', u'night', u'okai', u'old', u'omg', u'parti', u'peopl', u'phone', u'pic', u'plai', u'plan', u'poor', u'pretti', u'rain', u'read', u'readi', u'realli', u'right', u'run', u'sad', u'sai', u'said', u'saw', u'school', u'shop', u'sick', u'sleep', u'song', u'soon', u'sorri', u'sound', u'stai', u'star', u'start', u'stop', u'studi', u'stuff', u'suck', u'summer', u'sun', u'sundai', u'sure', u'talk', u'tell', u'thank', u'that', u'thing', u'think', u'thought', u'till', u'time', u'tire', u'todai', u'tomorrow', u'tonight', u'try', u'trying', u'tweet', u'twitter', u'ugh', u'updat', u'us', u'video', u'wai', u'wait', u'wan', u'wanna', u'want', u'watc', u'watch', u'weather', u'week', u'weekend', u'went', u'wish', u'won', u'wonder', u'wor', u'work', u'world', u'wow', u'yai', u'ye', u'yeah', u'year', u'yesterdai']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=200)\n",
    "ptweet = X_train.processed.tolist()\n",
    "\n",
    "X = vectorizer.fit_transform(ptweet)\n",
    "print(vectorizer.get_feature_names())\n",
    "# print(X.toarray())\n",
    "X = X.toarray()\n",
    "# X = np.asarray(X)\n",
    "# print type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2f46a925fdfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/priyendu/.local/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# overall.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/priyendu/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \"\"\"\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/priyendu/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    465\u001b[0m                               \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                               \u001b[0mneg_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                               sparse_output=self.sparse_output)\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/priyendu/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.pyc\u001b[0m in \u001b[0;36mlabel_binarize\u001b[0;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# pick out the known labels from y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0my_in_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0my_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_in_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/priyendu/.local/lib/python2.7/site-packages/numpy/lib/arraysetops.pyc\u001b[0m in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "clf = OneVsRestClassifier(svm.SVC(gamma=0.01, C=100., probability=True, class_weight='balanced', kernel='linear'))\n",
    "clf_output = clf.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
