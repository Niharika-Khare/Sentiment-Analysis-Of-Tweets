{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A                                                  F\n",
      "0  0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1  0  is upset that he can't update his Facebook by ...\n",
      "2  0  @Kenichan I dived many times for the ball. Man...\n",
      "3  0    my whole body feels itchy and like its on fire \n",
      "4  0  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../input_data/data.csv\", names=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"])\n",
    "df = df.drop([\"B\",\"C\",\"D\",\"E\"], axis=1)\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from porter_stemmer import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "def processTweet(tweet):\n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    #remove @username\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    # Remove tickers\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # To lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    # Remove Punctuation and split 's, 't, 've with a space for filter\n",
    "    tweet = re.sub(r'[' + string.punctuation.replace('@', '') + ']+', ' ', tweet)\n",
    "    # Remove words with 2 or fewer letters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    tweet = re.sub(' +', ' ',tweet)\n",
    "    # Remove single space remaining at the front of the tweet.\n",
    "    tweet = tweet.lstrip(' ')  \n",
    "    # Removing Stopwords from tweet using sklearn.feature_extraction\n",
    "    split_list = tweet.split(\" \")\n",
    "    tweet = [ word for word in split_list if word not in stop_words.ENGLISH_STOP_WORDS ]\n",
    "    # Stemming the \n",
    "    ps = PorterStemmer()\n",
    "#     print tweet\n",
    "#     t = []\n",
    "#     for word in tweet:\n",
    "#         print word\n",
    "#         t.append(ps.stem(word))\n",
    "    tweet = [ ps.stem(word) for word in tweet ] \n",
    "#     tweet = t\n",
    "    tweet = ' '.join(tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "processed_data = list()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    processed_data.append(processTweet(row['F']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>F</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww bummer shoulda got david carr dai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook tex result school todai b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dive time ball manag save rest bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>bodi feel itchi like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behav mad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A                                                  F  \\\n",
       "0  0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1  0  is upset that he can't update his Facebook by ...   \n",
       "2  0  @Kenichan I dived many times for the ball. Man...   \n",
       "3  0    my whole body feels itchy and like its on fire    \n",
       "4  0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                           processed  \n",
       "0            awww bummer shoulda got david carr dai   \n",
       "1  upset updat facebook tex result school todai b...  \n",
       "2               dive time ball manag save rest bound  \n",
       "3                              bodi feel itchi like   \n",
       "4                                         behav mad   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed'] = processed_data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df['processed']\n",
    "Y = df['A']\n",
    "X_train_val, X_test , Y_train_val, Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val,Y_train_val,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, Y_train],axis='columns').reset_index(drop=True)\n",
    "train_df.to_csv(\"../input_data/train_df.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.concat([X_val, Y_val],axis='columns').reset_index(drop=True)\n",
    "validation_df.to_csv(\"../input_data/validation_df.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test, Y_test],axis='columns').reset_index(drop=True)\n",
    "test_df.to_csv(\"../input_data/test_df.csv\", sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
