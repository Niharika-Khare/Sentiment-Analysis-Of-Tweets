{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#      ****     SENTIMENT ANALYSIS OF TWEETS       ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from porter_stemmer import PorterStemmer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./input_data/tweet_data.csv\",names = [\"sentiment\",\"date\",\"user\",\"xgfg\",\"dxgfd\",\"tweet\"] , encoding='latin-1')\n",
    "data = data.drop(columns=[\"date\",\"user\",\"xgfg\",\"dxgfd\"])\n",
    "data.head(10)\n",
    "print (data.iloc[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    \n",
    "    #remove @username\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    \n",
    "    # Remove tickers\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    \n",
    "    # To lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    \n",
    "    # Remove hashtags\n",
    "#     tweet = re.sub(r'#\\w*', '', tweet)\n",
    "\n",
    "    # Remove Punctuation and split 's, 't, 've with a space for filter\n",
    "    tweet = re.sub(r'[' + string.punctuation.replace('@', '') + ']+', ' ', tweet)\n",
    "    \n",
    "    # Remove words with 2 or fewer letters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    \n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    tweet = re.sub(' +', ' ',tweet)\n",
    "    \n",
    "    # Remove single space remaining at the front of the tweet.\n",
    "    tweet = tweet.lstrip(' ')  \n",
    "    \n",
    "    # Removing Stopwords from tweet using sklearn.feature_extraction\n",
    "    split_list = tweet.split(\" \")\n",
    "    tweet = [ word for word in split_list if word not in stop_words.ENGLISH_STOP_WORDS ]\n",
    "    \n",
    "    # Stemming the \n",
    "    ps = PorterStemmer()\n",
    "    tweet = [ ps.stem(word) for word in tweet ]\n",
    "    tweet = ' '.join(tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "processed_data = list()\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    processed_data.append(processTweet(row['tweet']))\n",
    "    \n",
    "# data['processed'] = processed_data\n",
    "# data.head()                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww bummer shoulda got david carr dai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook tex result school todai b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dive time ball manag save rest bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>bodi feel itchi like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behav mad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                              tweet  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                           processed  \n",
       "0            awww bummer shoulda got david carr dai   \n",
       "1  upset updat facebook tex result school todai b...  \n",
       "2               dive time ball manag save rest bound  \n",
       "3                              bodi feel itchi like   \n",
       "4                                         behav mad   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['processed'] = processed_data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['processed']\n",
    "Y = data['sentiment']\n",
    "X_train_val, X_test , Y_train_val, Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val,Y_train_val,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(str):\n",
    "#     return str.split(\" \")\n",
    "\n",
    "# def stemming(list_of_tokens):\n",
    "#     ps = PorterStemmer()\n",
    "#     return [ ps.stem(word) for word in list_of_tokens ] \n",
    "\n",
    "# word_list = []\n",
    "# for st in data.iloc[:10,1]:\n",
    "#     tokens = tokenize(st)\n",
    "#     stemmed = stemming(tokens)\n",
    "#     for wd in stemmed:\n",
    "#         if wd in ENGLISH_STOP_WORDS:\n",
    "# #             print wd\n",
    "#             stemmed.remove(wd)\n",
    "#         if wd == '':\n",
    "#             stemmed.remove(wd)\n",
    "#     word_list += [stemmed]\n",
    "    \n",
    "# print word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_pattern(input_txt, pattern): \n",
    "#     r = re.findall(pattern, input_txt)\n",
    "#     for i in r:\n",
    "#         input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "#     return input_txt\n",
    "\n",
    "# # remove twitter handles (@user)\n",
    "# data.iloc[:10,1] = np.vectorize(remove_pattern)(data.iloc[:10,1], \"@[\\w]*\")\n",
    "# print (data.iloc[:10,1])\n",
    "\n",
    "# # # remove url\n",
    "# # data.iloc[:10,1] = np.vectorize(remove_pattern)(data.iloc[:10,1],)# \"^https?:\\/\\/.*[\\r\\n]*\")#, text, flags=re.MULTILINE))\n",
    "# # print (data.iloc[:10,1])\n",
    "\n",
    "# # remove special characters, numbers, punctuations\n",
    "# data.iloc[:10,1] = data.iloc[:10,1].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "# print (data.iloc[:10,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
