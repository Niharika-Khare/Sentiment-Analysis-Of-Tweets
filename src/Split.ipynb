{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Countvectorizer and TFIDF with unigram and bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input_data/clean_tweet_without_NaN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.text\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 1553896 entries with 50.02% negative, 49.98% positive\n",
      "Validation set has total 15856 entries with 50.26% negative, 49.74% positive\n",
      "Test set has total 15857 entries with 49.90% negative, 50.10% positive\n"
     ]
    }
   ],
   "source": [
    "print \"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train),\n",
    "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
    "                                                                            (len(x_train[y_train == 4]) / (len(x_train)*1.))*100)\n",
    "print \"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_validation),\n",
    "                                                                             (len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,\n",
    "                                                                            (len(x_validation[y_validation == 4]) / (len(x_validation)*1.))*100)\n",
    "print \"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_test),\n",
    "                                                                             (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
    "                                                                            (len(x_test[y_test == 4]) / (len(x_test)*1.))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test == 0]) / (len(x_test)*1.) > 0.5:\n",
    "        null_accuracy = len(x_test[y_test == 0]) / (len(x_test)*1.)\n",
    "    else:\n",
    "        null_accuracy = 1. - (len(x_test[y_test == 0]) / (len(x_test)*1.))\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print \"null accuracy: {0:.2f}%\".format(null_accuracy*100)\n",
    "    print \"accuracy score: {0:.2f}%\".format(accuracy*100)\n",
    "    if accuracy > null_accuracy:\n",
    "        print \"model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100)\n",
    "    elif accuracy == null_accuracy:\n",
    "        print \"model has the same accuracy with the null accuracy\"\n",
    "    else:\n",
    "        print \"model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100)\n",
    "    print \"train and test time: {0:.2f}s\".format(train_test_time)\n",
    "    print \"-\"*80\n",
    "    return accuracy, train_test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "tvec = TfidfVectorizer()\n",
    "lr = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "svm_obj = LinearSVC(C=0.1)\n",
    "\n",
    "n_features = np.arange(10000,100001,10000)\n",
    "\n",
    "def nfeature_accuracy_checker(vectorizer=cvec, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=lr):\n",
    "    result = []\n",
    "    print (classifier)\n",
    "    print \"\\n\"\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        print \"Validation result for {} features\".format(n)\n",
    "        nfeature_accuracy,tt_time = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        result.append((n,nfeature_accuracy,tt_time))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR UNIGRAM WITH STOP WORDS (Tfidf)\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rushit/.local/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 50.26%\n",
      "accuracy score: 77.03%\n",
      "model is 26.77% more accurate than null accuracy\n",
      "train and test time: 28.34s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.20%\n",
      "model is 26.94% more accurate than null accuracy\n",
      "train and test time: 32.70s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.18%\n",
      "model is 26.92% more accurate than null accuracy\n",
      "train and test time: 31.02s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.24%\n",
      "model is 26.98% more accurate than null accuracy\n",
      "train and test time: 34.98s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.23%\n",
      "model is 26.97% more accurate than null accuracy\n",
      "train and test time: 36.44s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.18%\n",
      "model is 26.92% more accurate than null accuracy\n",
      "train and test time: 36.07s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.21%\n",
      "model is 26.95% more accurate than null accuracy\n",
      "train and test time: 36.25s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.27%\n",
      "model is 27.01% more accurate than null accuracy\n",
      "train and test time: 34.10s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.32%\n",
      "model is 27.06% more accurate than null accuracy\n",
      "train and test time: 37.15s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.31%\n",
      "model is 27.06% more accurate than null accuracy\n",
      "train and test time: 34.89s\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 5min 40s, sys: 2.85 s, total: 5min 43s\n",
      "Wall time: 5min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"RESULT FOR UNIGRAM WITH STOP WORDS (Tfidf)\\n\"\n",
    "feature_result_ugt = nfeature_accuracy_checker(vectorizer=tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR BIGRAM WITH STOP WORDS (Tfidf)\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.31%\n",
      "model is 27.05% more accurate than null accuracy\n",
      "train and test time: 67.98s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.57%\n",
      "model is 27.31% more accurate than null accuracy\n",
      "train and test time: 67.45s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.97%\n",
      "model is 27.71% more accurate than null accuracy\n",
      "train and test time: 73.04s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 77.98%\n",
      "model is 27.72% more accurate than null accuracy\n",
      "train and test time: 74.54s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 78.08%\n",
      "model is 27.82% more accurate than null accuracy\n",
      "train and test time: 70.37s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 78.17%\n",
      "model is 27.91% more accurate than null accuracy\n",
      "train and test time: 70.46s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 78.17%\n",
      "model is 27.91% more accurate than null accuracy\n",
      "train and test time: 70.63s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 78.11%\n",
      "model is 27.85% more accurate than null accuracy\n",
      "train and test time: 71.04s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 78.22%\n",
      "model is 27.96% more accurate than null accuracy\n",
      "train and test time: 71.02s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "null accuracy: 50.26%\n",
      "accuracy score: 78.13%\n",
      "model is 27.88% more accurate than null accuracy\n",
      "train and test time: 72.41s\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 11min 39s, sys: 12 s, total: 11min 51s\n",
      "Wall time: 11min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"RESULT FOR BIGRAM WITH STOP WORDS (Tfidf)\\n\"\n",
    "feature_result_bgt = nfeature_accuracy_checker(vectorizer=tvec,ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fb_df = pd.read_csv(\"../input_data/clean_fb.csv\")\n",
    "fb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
